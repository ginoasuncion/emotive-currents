{
  "experiment_name": "gemma-3n-e4b-it-emotion-classification",
  "model": "google/gemma-3n-e4b-it",
  "temperature": 0.1,
  "samples_per_emotion": 3,
  "prompt_strategy": "zero-shot",
  "random_seed": 42,
  "prompt": {
    "template": "You are an expert in emotion analysis. Given a sentence or paragraph, your task is to estimate the emotional intensity for each of 28 categories defined in the GoEmotions dataset. Each category should be scored between 0.0 (not present) and 1.0 (very strongly present). Multiple emotions may be present at once, or the text may be neutral.\n\nIMPORTANT: You must respond with ONLY a valid JSON object. Do not include any other text, explanations, or markdown formatting. The JSON must use double quotes for keys and values.\n\nHere are the 28 categories:\n- admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral\n\nText to analyze: {input_text}\n\nRespond with a JSON object containing scores for each emotion:",
    "variables": ["input_text"]
  },
  "description": "Gemma 3n E4B-it is optimized for efficient execution on mobile and low-resource devices, such as phones, laptops, and tablets. It supports multimodal inputs—including text, visual data, and audio—enabling diverse tasks such as text generation, speech recognition, translation, and image analysis. Leveraging innovations like Per-Layer Embedding (PLE) caching and the MatFormer architecture, Gemma 3n dynamically manages memory usage and computational load by selectively activating model parameters, significantly reducing runtime resource requirements. This model supports a wide linguistic range (trained in over 140 languages) and features a flexible 32K token context window. Gemma 3n can selectively load parameters, optimizing memory and computational efficiency based on the task or device capabilities, making it well-suited for privacy-focused, offline-capable applications and on-device AI solutions.",
  "metadata": {
    "provider": "Google",
    "model_family": "Gemma",
    "version": "3n E4B-it",
    "expected_performance": "Efficient mobile-optimized model with multimodal capabilities",
    "context_window": "32K tokens",
    "languages": "140+ languages"
  }
} 
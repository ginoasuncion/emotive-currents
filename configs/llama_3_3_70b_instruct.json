{
  "experiment_name": "llama-3.3-70b-instruct-emotion-classification",
  "model": "meta-llama/llama-3.3-70b-instruct",
  "temperature": 0.1,
  "samples_per_emotion": 3,
  "prompt_strategy": "zero-shot",
  "random_seed": 42,
  "prompt": {
    "template": "You are an expert in emotion analysis. Given a sentence or paragraph, your task is to estimate the emotional intensity for each of 28 categories defined in the GoEmotions dataset. Each category should be scored between 0.0 (not present) and 1.0 (very strongly present). Multiple emotions may be present at once, or the text may be neutral.\n\nIMPORTANT: You must respond with ONLY a valid JSON object. Do not include any other text, explanations, or markdown formatting. The JSON must use double quotes for keys and values.\n\nHere are the 28 categories:\n{emotion_labels}\n\nInput: \"{input_text}\"\n\nRespond with ONLY the JSON object:",
    "variables": {
      "emotion_labels": "admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral"
    },
    "output_format": "JSON",
    "instructions": "Return only valid JSON with emotion scores between 0.0 and 1.0. Use double quotes for all keys and values. Do not include any other text or formatting."
  },
  "description": "Emotion Classification Experiment using Meta Llama 3.3 70B Instruct\n\nThe Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nThis experiment evaluates the performance of Llama 3.3 70B Instruct on the GoEmotions dataset for multi-label emotion classification. The model is tested using zero-shot prompting with a comprehensive prompt that includes all 28 categories (27 emotions + neutral).\n\nModel: meta-llama/llama-3.3-70b-instruct\nTemperature: 0.1\nDataset: GoEmotions validation set\nSampling: Stratified sampling with exactly 3 samples per emotion\nReproducibility: Fixed random seed (42) ensures same dataset on each run\nMetrics: Macro/Micro F1, Precision, Recall, Top-2/3 Accuracy/Precision/Recall/F1, Per-emotion performance\nOutput: CSV with detailed results, MLflow tracking for all metrics\n\nNote: Llama 3.3 70B Instruct is expected to achieve strong performance on emotion classification due to its advanced multilingual and instruction following capabilities.",
  "metadata": {
    "model_provider": "Meta",
    "model_family": "Llama",
    "model_version": "3.3 70B Instruct",
    "expected_performance": "Strong",
    "use_case": "Multi-label emotion classification",
    "dataset": "GoEmotions",
    "notes": "Llama 3.3 70B Instruct is optimized for multilingual dialogue and instruction following, and outperforms many open and closed models on industry benchmarks."
  }
} 